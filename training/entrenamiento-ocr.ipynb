{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6648498c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-04T11:07:33.355838Z",
     "iopub.status.busy": "2025-11-04T11:07:33.355536Z",
     "iopub.status.idle": "2025-11-04T11:07:35.392183Z",
     "shell.execute_reply": "2025-11-04T11:07:35.391110Z"
    },
    "papermill": {
     "duration": 2.045854,
     "end_time": "2025-11-04T11:07:35.394295",
     "exception": false,
     "start_time": "2025-11-04T11:07:33.348441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/matriculas/gt.txt\n",
      "/kaggle/input/matriculas/images/1f855390ac408473250da4281ddecbfa9888a8614d50f5d69de09afc6f548c27_1.jpg\n",
      "/kaggle/input/matriculas/images/1f7780a0132588c410678afe1c4e9bdad9a6aa5d35a4cdb47a57e977b56bdfdc_1.jpg\n",
      "/kaggle/input/matriculas/images/2dc487a1f375370bd9af2448a2a4bef19e69a6a1ab8ff54b88e681155b2c2edb_1.jpg\n",
      "/kaggle/input/matriculas/images/1de0301fcb918e5ee9f020cc343a430a89e80afde2b8a931bdd1e1f40bcb642a_1.jpg\n",
      "/kaggle/input/matriculas/images/0aff94b0cc4cfef9f1c7b1aca3be6b5d10b2528f1a2310306a185124ef3043cc_1.jpg\n",
      "/kaggle/input/matriculas/images/0e1e9fd3b5bfe7a712de9a2c526c03e3135a3aa3906294e1bae26bfbac52886d_1.jpg\n",
      "/kaggle/input/matriculas/images/4b334e9707ed29695f8eccd4525ae7956c353f5aa130347e10e0af621022e066_1.jpg\n",
      "/kaggle/input/matriculas/images/1f30d2f1a6dd81c2aa3405ba3479f365d6e0a8d8436aa28fa4bb4ae9421a3d0c_1.jpg\n",
      "/kaggle/input/matriculas/images/0a7b57cd65e08970cacc537a6becba9e59cd91d63c41cc65913f0ca029e0a230_1.jpg\n",
      "/kaggle/input/matriculas/images/2e208ecead0a4bc105969082c537b7bf4bcae0956abb361b16e2cdaaf2dfc55c_1.jpg\n",
      "/kaggle/input/matriculas/images/0dbeabcefc59ce5bb60f9023a9ae975efd1384ab45f3b8ad144b59bc369123e9_1.jpg\n",
      "/kaggle/input/matriculas/images/2d6bcd5227b5eea0105b6bb4e8d4e53ade2218d61aacd111349877fe3a939b39_1.jpeg\n",
      "/kaggle/input/matriculas/images/IMG_6019.jpg\n",
      "/kaggle/input/matriculas/images/IMG_6018.jpg\n",
      "/kaggle/input/matriculas/images/2d6bcd5227b5eea0105b6bb4e8d4e53ade2218d61aacd111349877fe3a939b39.jpeg\n",
      "/kaggle/input/matriculas/images/03efc2c9c798ed28520f2fa05f74fbcb2fecd862cfff48bc82872ba89c43f734_1.jpg\n",
      "/kaggle/input/matriculas/images/1d6a7e7dfafebc35d0ddb210fdfe3f2c711ee5aee8165b0093ee40c35e0ee3bd_1.jpg\n",
      "/kaggle/input/matriculas/images/1b958e7132e9b455f8b3e12c80ec8d332dddf49b1429222dc084d9cb20c09e7f_1.jpg\n",
      "/kaggle/input/matriculas/images/0f2a1e6b27d4f93da2ac1c1336bdbb94ce46cfb0fcce7f863614b71bf54405eb_1.jpg\n",
      "/kaggle/input/matriculas/images/IMG_6013.jpg\n",
      "/kaggle/input/matriculas/images/00a411625f65abd87bd054fbf8b6c2deb585407515a59fa2998abf36fcf280e6_1.jpg\n",
      "/kaggle/input/matriculas/images/1f46e58e6c5c2db36cf230aa1137a69cea4a1825f5f9692846ce46c353550b49.jpg\n",
      "/kaggle/input/matriculas/images/3a9f56ce9e41db4fdf9d5abe7d642de96baf02e33efe625c752bb868e31f47c9_1.jpg\n",
      "/kaggle/input/matriculas/images/0f4636dbfd7bd56a40ef1180572b2e4f6f3b7b8317dc1b6866eca7358facfe60_1.jpg\n",
      "/kaggle/input/matriculas/images/0f54593ce358e208c21d7a4adac363a284d46767068bdd8d31bb8b2161e9f617.jpg\n",
      "/kaggle/input/matriculas/images/1d0842d89fb36e8191c2f3ae595f0a94996b0343efec2eb064a9ee95e6a1ac16_1.jpg\n",
      "/kaggle/input/matriculas/images/03e841f92593d122199dcbc17fb9dcd86228a0baf529602efe663e1c2eebac25_1.jpg\n",
      "/kaggle/input/matriculas/images/2d595030cf5565acc8c384195bfcaf0e2f7eb877c6600cdf4c6a581ab60c3046_1.jpg\n",
      "/kaggle/input/matriculas/images/0f5497916aaefa1109b4d90c26d6d316c80ec0b8a9365e0c810134009827fc5c_1.jpg\n",
      "/kaggle/input/matriculas/images/03bd90e78aee31b616ced0278252fd16d2eb3620ab08ead55f600149a5c4004c_1.jpg\n",
      "/kaggle/input/matriculas/images/03b8ee37e75311f8b40f6a2a29cf25449d510ec2500e61bcf5d075ecc597e52d_1.jpg\n",
      "/kaggle/input/matriculas/images/1c4b2371b3b8b6db73b450b869a570239b659fd64e7e1e1ae1f643a55ed8891e_1.jpg\n",
      "/kaggle/input/matriculas/images/IMG_6017.jpg\n",
      "/kaggle/input/matriculas/images/0c0541f49b528e0be821c2c75394d5eba39e8523dc0711656e7b0e9de2826538_1.jpg\n",
      "/kaggle/input/matriculas/images/0e16c455fd6357d777a0a8f62dd8b2366e135aa94a7f3942764db4912f35a82f_1.jpg\n",
      "/kaggle/input/matriculas/images/0a80ed155afc5f79fcec1d4f0bea6409ea1c5cbe2748e63d2404340f41a5e576_1.jpg\n",
      "/kaggle/input/matriculas/images/IMG_6023.jpg\n",
      "/kaggle/input/matriculas/images/0d3d42ad5af64c2ac046169312e45cc4828dbb99b2d202382dba7f5e4355c513_1.jpg\n",
      "/kaggle/input/matriculas/images/IMG_6021.jpg\n",
      "/kaggle/input/matriculas/images/03efc2c9c798ed28520f2fa05f74fbcb2fecd862cfff48bc82872ba89c43f734.jpg\n",
      "/kaggle/input/matriculas/images/2c2fbfe082b4b0f27ae8ea6c1618cfb98384e6a970fda4aadc416fdaf43e04e1_1.jpg\n",
      "/kaggle/input/matriculas/images/2d8a67db72049053bc505d8fd7414592a52af42e53a34aabfb7fa2cdb787daa9_1.jpg\n",
      "/kaggle/input/matriculas/images/2f0ddd8a5a4f22bb5c173f2ba1e98a94ea953f819bf5765281cd340a203d3433_1.jpg\n",
      "/kaggle/input/matriculas/images/1ff990273407018b0352299f5e982ea217eb101402ad25de7bb8bc0aeba49ee6_1.jpg\n",
      "/kaggle/input/matriculas/images/1d18066355939f6597dd56962339cfce5649c4afee1345f3bb9289965cf0f00e_1.jpg\n",
      "/kaggle/input/matriculas/images/1ede43880af7ea2ecf9efc489befc7906ae9feedb0dd72d7f74bfe6442216107_1.jpg\n",
      "/kaggle/input/matriculas/images/0f54593ce358e208c21d7a4adac363a284d46767068bdd8d31bb8b2161e9f617_1.jpg\n",
      "/kaggle/input/matriculas/images/2d550743ca8bf5981252ab8d71a010add78f42ce4a228eba591f87a2e2cfbb94_1.jpg\n",
      "/kaggle/input/matriculas/images/2ca6f9eb7af1477817031cac116d119732efe82efc217e45ec3dc983c880a19a_1.jpg\n",
      "/kaggle/input/matriculas/images/1dbef2f4339284152a2eb1af833b9d699b67d5c8451da592f5d903649aa5e3f0_1.jpg\n",
      "/kaggle/input/matriculas/images/0cf1335d6e1c10e9bef243600af59249a2258beb8b26efc75ad27154b57888f0_1.jpg\n",
      "/kaggle/input/matriculas/images/1f46e58e6c5c2db36cf230aa1137a69cea4a1825f5f9692846ce46c353550b49_1.jpg\n",
      "/kaggle/input/matriculas/images/2c8e38abb5dc526588b53723f5857c376f1871e0e6dd53367932a587c0b59018_1.jpg\n",
      "/kaggle/input/matriculas/images/01cb39be7599009fe0f3caf5d97e22854ebcaf57259fb0ab75efb4a4d6db1a0e_1.jpg\n",
      "/kaggle/input/matriculas/images/0f6bc9cea7f38650e5690d87a900fff67e3119052472e508b0b97244adf33688_1.jpg\n",
      "/kaggle/input/matriculas/images/0fa4112b0123f7dfdf03baf1dc8e8d8d87dec16853c36cc079b8f2dc97c7f5bd_1.jpg\n",
      "/kaggle/input/matriculas/images/0e32ae0a356ce70dd5602403d17937461fd930f3b258907917fb5394b306e9d1.jpeg\n",
      "/kaggle/input/matriculas/images/IMG_6020.jpg\n",
      "/kaggle/input/matriculas/images/04d4e35a9fef9f875a7e4f47f111b570d512d7d8faf1b11362557fc328fb29ad_1.jpg\n",
      "/kaggle/input/matriculas/images/0b47c45e9f1b83186ac3555aea3c03b34118846e4d56901927b945fb32adf015_1.jpg\n",
      "/kaggle/input/matriculas/images/2b3d42c90b672b58efe8f288d3436a38b46712817d6da6c27d47a5ab3258a75f_1.jpg\n",
      "/kaggle/input/matriculas/images/2c88403c0a30c150e98b22a1adcdc98570c18650329ef4df97e56720c51afb9c_1.jpg\n",
      "/kaggle/input/matriculas/images/IMG_6015.jpg\n",
      "/kaggle/input/matriculas/images/2dc91cadaabf6d02dabb9cd6706f1f9ae3e4a2a21ecd12965d1140f16dde0c6f_1.jpg\n",
      "/kaggle/input/matriculas/images/IMG_6014.jpg\n",
      "/kaggle/input/matriculas/images/0e32ae0a356ce70dd5602403d17937461fd930f3b258907917fb5394b306e9d1_1.jpeg\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5d46e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:07:35.402729Z",
     "iopub.status.busy": "2025-11-04T11:07:35.402334Z",
     "iopub.status.idle": "2025-11-04T11:07:47.886495Z",
     "shell.execute_reply": "2025-11-04T11:07:47.885337Z"
    },
    "papermill": {
     "duration": 12.490265,
     "end_time": "2025-11-04T11:07:47.888281",
     "exception": false,
     "start_time": "2025-11-04T11:07:35.398016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import re\n",
    "import math\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1abe3875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:07:47.896697Z",
     "iopub.status.busy": "2025-11-04T11:07:47.896206Z",
     "iopub.status.idle": "2025-11-04T11:07:47.902865Z",
     "shell.execute_reply": "2025-11-04T11:07:47.901835Z"
    },
    "papermill": {
     "duration": 0.013097,
     "end_time": "2025-11-04T11:07:47.904861",
     "exception": false,
     "start_time": "2025-11-04T11:07:47.891764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_STEM = \"matriculas\" # <--- EDITA AQUÃ\n",
    "DATASET_PATH = f\"/kaggle/input/{DATASET_STEM}\"\n",
    "IMG_DIR = os.path.join(DATASET_PATH, \"images\")\n",
    "GT_FILE = os.path.join(DATASET_PATH, \"gt.txt\")\n",
    "\n",
    "\n",
    "OUTPUT_MODEL = \"/kaggle/working/ocr_ctc.pt\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 30\n",
    "LR = 1e-3\n",
    "IMG_W, IMG_H = 128, 32 # ancho x alto para CRNN (ancho grande, alto pequeÃ±o)\n",
    "\n",
    "\n",
    "# Caracteres permitidos: blank en el Ã­ndice 0\n",
    "CHARS = \"-0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\" # '-' = blank\n",
    "char2idx = {c: i for i, c in enumerate(CHARS)}\n",
    "idx2char = {i: c for i, c in enumerate(CHARS)}\n",
    "NUM_CLASSES = len(CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8d7896",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:07:47.913762Z",
     "iopub.status.busy": "2025-11-04T11:07:47.912934Z",
     "iopub.status.idle": "2025-11-04T11:07:47.983883Z",
     "shell.execute_reply": "2025-11-04T11:07:47.982739Z"
    },
    "papermill": {
     "duration": 0.077253,
     "end_time": "2025-11-04T11:07:47.985698",
     "exception": false,
     "start_time": "2025-11-04T11:07:47.908445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total raw lines: 66\n",
      "Total extracted samples: 72\n",
      "Total samples with images: 72\n",
      "Total missing files: 0\n",
      "                                            filename     text\n",
      "0  1f46e58e6c5c2db36cf230aa1137a69cea4a1825f5f969...  3654MYH\n",
      "1  1dbef2f4339284152a2eb1af833b9d699b67d5c8451da5...  0624LXM\n",
      "2  1d18066355939f6597dd56962339cfce5649c4afee1345...  4517MFC\n",
      "3  1d0842d89fb36e8191c2f3ae595f0a94996b0343efec2e...  3561CXR\n",
      "4  1c4b2371b3b8b6db73b450b869a570239b659fd64e7e1e...  0576MSH\n",
      "5  1b958e7132e9b455f8b3e12c80ec8d332dddf49b142922...  4967LYL\n",
      "6  0fa4112b0123f7dfdf03baf1dc8e8d8d87dec16853c36c...  0476MNN\n",
      "7  0f6bc9cea7f38650e5690d87a900fff67e3119052472e5...  2377JZG\n",
      "8  0f5497916aaefa1109b4d90c26d6d316c80ec0b8a9365e...  4436MLF\n",
      "9  0f5497916aaefa1109b4d90c26d6d316c80ec0b8a9365e...  6801HMT\n"
     ]
    }
   ],
   "source": [
    "assert os.path.exists(IMG_DIR), f\"No existe {IMG_DIR}. AsegÃºrate de subir las imÃ¡genes al dataset.\"\n",
    "assert os.path.exists(GT_FILE), f\"No existe {GT_FILE}. AsegÃºrate de que gt.txt estÃ© en el dataset.\"\n",
    "\n",
    "\n",
    "raw_lines = []\n",
    "with open(GT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            raw_lines.append(line)\n",
    "\n",
    "\n",
    "clean_samples = []\n",
    "\n",
    "\n",
    "# Regex para matrÃ­culas tÃ­picas: 4 dÃ­gitos opcionales + letras/dÃ­gitos (flexible)\n",
    "# Ajusta si tus matrÃ­culas tienen otro formato\n",
    "plate_regex = re.compile(r\"([0-9]{3,4}\\s*[A-Z0-9]{2,6})\")\n",
    "\n",
    "\n",
    "for line in raw_lines:\n",
    "    # primer split por coma (nombre de archivo, resto)\n",
    "    parts = line.split(\",\", 1)\n",
    "    if len(parts) == 1:\n",
    "        # intenta espacio separado\n",
    "        parts = line.split(maxsplit=1)\n",
    "        if len(parts) == 1:\n",
    "            continue\n",
    "    filename = parts[0].strip().strip('\"')\n",
    "    rest = parts[1].strip()\n",
    "\n",
    "\n",
    "    # extraer todas las coincidencias de matrÃ­cula\n",
    "    matches = plate_regex.findall(rest)\n",
    "    if not matches:\n",
    "        # Ãºltima oportunidad: todo lo que estÃ¡ entre comillas\n",
    "        quoted = re.findall(r'\"([^\"]+)\"', rest)\n",
    "        if quoted:\n",
    "            # dividir por comillas dobles pegadas\n",
    "            for q in quoted:\n",
    "                q = q.replace('\"\"', '\"')\n",
    "                m = plate_regex.findall(q)\n",
    "                if m:\n",
    "                    for mm in m:\n",
    "                        clean_samples.append((filename, mm.replace(\" \", \"\")))\n",
    "            continue\n",
    "        else:\n",
    "            # intentar tomar todo el resto como label\n",
    "            lab = rest.replace('\"', '').strip()\n",
    "            if lab:\n",
    "                clean_samples.append((filename, lab.replace(\" \", \"\")))\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    for m in matches:\n",
    "        clean_samples.append((filename, m.replace(\" \", \"\")))\n",
    "\n",
    "\n",
    "# Filtrar por existencia de archivo\n",
    "clean_filtered = []\n",
    "missing = []\n",
    "for fn, txt in clean_samples:\n",
    "    p = os.path.join(IMG_DIR, fn)\n",
    "    if os.path.exists(p):\n",
    "        clean_filtered.append((fn, txt))\n",
    "    else:\n",
    "        missing.append(fn)\n",
    "\n",
    "\n",
    "print(f\"Total raw lines: {len(raw_lines)}\")\n",
    "print(f\"Total extracted samples: {len(clean_samples)}\")\n",
    "print(f\"Total samples with images: {len(clean_filtered)}\")\n",
    "print(f\"Total missing files: {len(set(missing))}\")\n",
    "if len(set(missing)) > 0:\n",
    "    print(\"Ejemplos missing:\", list(set(missing))[:10])\n",
    "\n",
    "\n",
    "# Crear DataFrame final\n",
    "df = pd.DataFrame(clean_filtered, columns=[\"filename\", \"text\"]).drop_duplicates().reset_index(drop=True)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "382ea6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:07:47.993959Z",
     "iopub.status.busy": "2025-11-04T11:07:47.993638Z",
     "iopub.status.idle": "2025-11-04T11:07:48.003544Z",
     "shell.execute_reply": "2025-11-04T11:07:48.002606Z"
    },
    "papermill": {
     "duration": 0.015732,
     "end_time": "2025-11-04T11:07:48.005076",
     "exception": false,
     "start_time": "2025-11-04T11:07:47.989344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PlatesDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, max_len=10):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.max_len = max_len\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    def text_to_labels(self, text):\n",
    "        labels = []\n",
    "        for ch in text:\n",
    "            if ch in char2idx:\n",
    "                labels.append(char2idx[ch])\n",
    "        return labels\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            # imagen corrupta -> devolver zeros\n",
    "            img = np.zeros((IMG_H, IMG_W), dtype=np.uint8)\n",
    "        # resize manteniendo ratio y rellenando\n",
    "        h, w = img.shape\n",
    "        new_h = IMG_H\n",
    "        new_w = int(w * (IMG_H / h))\n",
    "        new_w = min(new_w, IMG_W)\n",
    "        img = cv2.resize(img, (new_w, new_h))\n",
    "        if new_w < IMG_W:\n",
    "            pad = np.full((IMG_H, IMG_W - new_w), 255, dtype=np.uint8)\n",
    "            img = np.concatenate([img, pad], axis=1)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = img[np.newaxis, ...] # (1, H, W)\n",
    "        \n",
    "        \n",
    "        labels = self.text_to_labels(row['text'])\n",
    "        labels = np.array(labels, dtype=np.int32)\n",
    "        return torch.tensor(img).float(), torch.tensor(labels).int(), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e2c6fe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:07:48.013435Z",
     "iopub.status.busy": "2025-11-04T11:07:48.013125Z",
     "iopub.status.idle": "2025-11-04T11:07:48.048013Z",
     "shell.execute_reply": "2025-11-04T11:07:48.047015Z"
    },
    "papermill": {
     "duration": 0.040896,
     "end_time": "2025-11-04T11:07:48.049767",
     "exception": false,
     "start_time": "2025-11-04T11:07:48.008871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(64*16, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous().view(b, w, c*h)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CRNN(NUM_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "822577d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:07:48.057702Z",
     "iopub.status.busy": "2025-11-04T11:07:48.057386Z",
     "iopub.status.idle": "2025-11-04T11:07:48.062966Z",
     "shell.execute_reply": "2025-11-04T11:07:48.061969Z"
    },
    "papermill": {
     "duration": 0.011464,
     "end_time": "2025-11-04T11:07:48.064667",
     "exception": false,
     "start_time": "2025-11-04T11:07:48.053203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs, labels, lengths = zip(*batch)\n",
    "    imgs = torch.stack(imgs)\n",
    "    labels_concat = torch.cat([l for l in labels])\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    return imgs, labels_concat, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d4a3615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:07:48.073007Z",
     "iopub.status.busy": "2025-11-04T11:07:48.072691Z",
     "iopub.status.idle": "2025-11-04T11:07:48.078496Z",
     "shell.execute_reply": "2025-11-04T11:07:48.077398Z"
    },
    "papermill": {
     "duration": 0.011912,
     "end_time": "2025-11-04T11:07:48.080144",
     "exception": false,
     "start_time": "2025-11-04T11:07:48.068232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs, labels, lengths = zip(*batch)\n",
    "    imgs = torch.stack(imgs)\n",
    "    labels_concat = torch.cat([l for l in labels])\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    return imgs, labels_concat, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "208c3058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:07:48.088548Z",
     "iopub.status.busy": "2025-11-04T11:07:48.087845Z",
     "iopub.status.idle": "2025-11-04T11:07:48.098018Z",
     "shell.execute_reply": "2025-11-04T11:07:48.097087Z"
    },
    "papermill": {
     "duration": 0.015704,
     "end_time": "2025-11-04T11:07:48.099403",
     "exception": false,
     "start_time": "2025-11-04T11:07:48.083699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 65, Val samples: 7\n"
     ]
    }
   ],
   "source": [
    "train_df = df.sample(frac=0.9, random_state=42).reset_index(drop=True)\n",
    "val_df = df.drop(train_df.index).reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_ds = PlatesDataset(train_df, IMG_DIR)\n",
    "val_ds = PlatesDataset(val_df, IMG_DIR)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}, Val samples: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44289a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:07:48.107545Z",
     "iopub.status.busy": "2025-11-04T11:07:48.107195Z",
     "iopub.status.idle": "2025-11-04T11:07:48.116059Z",
     "shell.execute_reply": "2025-11-04T11:07:48.114974Z"
    },
    "papermill": {
     "duration": 0.014871,
     "end_time": "2025-11-04T11:07:48.117694",
     "exception": false,
     "start_time": "2025-11-04T11:07:48.102823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1), (2,1)),  # conserva ancho\n",
    "            nn.Conv2d(256, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1), (2,1))\n",
    "        )\n",
    "\n",
    "        # ðŸ”¹ Cambiamos el input_size a 1024 para que coincida con la salida real del CNN\n",
    "        self.rnn = nn.LSTM(1024, 256, num_layers=2, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.view(b, c*h, w).permute(0, 2, 1)  # (batch, width, features)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8f6abfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:07:48.126401Z",
     "iopub.status.busy": "2025-11-04T11:07:48.126078Z",
     "iopub.status.idle": "2025-11-04T11:07:48.237277Z",
     "shell.execute_reply": "2025-11-04T11:07:48.236309Z"
    },
    "papermill": {
     "duration": 0.117256,
     "end_time": "2025-11-04T11:07:48.238957",
     "exception": false,
     "start_time": "2025-11-04T11:07:48.121701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CRNN(NUM_CLASSES).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "\n",
    "\n",
    "# helper para calcular input_lengths\n",
    "\n",
    "\n",
    "def train_epoch(loader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, labels_concat, lengths in tqdm(loader):\n",
    "        imgs = imgs.to(device)\n",
    "        labels_concat = labels_concat.to(device)\n",
    "        batch = imgs.size(0)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs) # (B, W, C)\n",
    "        outputs = outputs.log_softmax(2)\n",
    "        outputs = outputs.permute(1,0,2) # (W, B, C) para CTCLoss\n",
    "        \n",
    "        \n",
    "        input_lengths = torch.full(size=(batch,), fill_value=outputs.size(0), dtype=torch.long).to(device)\n",
    "        target_lengths = lengths.to(device)\n",
    "        \n",
    "        \n",
    "        loss = criterion(outputs, labels_concat, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def val_epoch(loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels_concat, lengths in tqdm(loader):\n",
    "            imgs = imgs.to(device)\n",
    "            labels_concat = labels_concat.to(device)\n",
    "            batch = imgs.size(0)\n",
    "            outputs = model(imgs)\n",
    "            outputs = outputs.log_softmax(2)\n",
    "            outputs = outputs.permute(1,0,2)\n",
    "            input_lengths = torch.full(size=(batch,), fill_value=outputs.size(0), dtype=torch.long).to(device)\n",
    "            target_lengths = lengths.to(device)\n",
    "            loss = criterion(outputs, labels_concat, input_lengths, target_lengths)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f750261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T11:07:48.247224Z",
     "iopub.status.busy": "2025-11-04T11:07:48.246895Z",
     "iopub.status.idle": "2025-11-04T11:14:18.960558Z",
     "shell.execute_reply": "2025-11-04T11:14:18.959132Z"
    },
    "papermill": {
     "duration": 390.720571,
     "end_time": "2025-11-04T11:14:18.963072",
     "exception": false,
     "start_time": "2025-11-04T11:07:48.242501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.23s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - train_loss: 9.1616 - val_loss: 5.1755\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.74s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 - train_loss: 4.1725 - val_loss: 3.8328\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.74s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 - train_loss: 3.7082 - val_loss: 3.6408\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.81s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 - train_loss: 3.6104 - val_loss: 3.6454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.05s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 - train_loss: 3.6034 - val_loss: 3.5205\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:10<00:00,  3.57s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 - train_loss: 3.4101 - val_loss: 3.5546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:11<00:00,  3.77s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 - train_loss: 3.4625 - val_loss: 3.5255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 - train_loss: 3.4224 - val_loss: 3.5517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.19s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 - train_loss: 3.4860 - val_loss: 3.5577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.28s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 - train_loss: 3.4156 - val_loss: 3.4942\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.55s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 - train_loss: 3.5109 - val_loss: 3.4582\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.45s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 - train_loss: 3.5596 - val_loss: 3.4546\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.55s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 - train_loss: 3.3567 - val_loss: 3.4860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.58s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 - train_loss: 3.5687 - val_loss: 3.4806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.59s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 - train_loss: 3.5494 - val_loss: 3.4401\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.65s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 - train_loss: 3.4484 - val_loss: 3.4043\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.62s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 - train_loss: 3.4212 - val_loss: 3.3836\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.65s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 - train_loss: 3.3412 - val_loss: 3.3852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.59s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 - train_loss: 3.3901 - val_loss: 3.3799\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:14<00:00,  4.69s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 - train_loss: 3.4590 - val_loss: 3.3604\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.62s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 - train_loss: 3.4431 - val_loss: 3.3440\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.57s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 - train_loss: 3.3651 - val_loss: 3.3290\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.58s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 - train_loss: 3.2145 - val_loss: 3.3069\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:14<00:00,  4.69s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 - train_loss: 3.3038 - val_loss: 3.2984\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:14<00:00,  4.74s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 - train_loss: 3.2463 - val_loss: 3.2730\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:14<00:00,  4.76s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 - train_loss: 3.1394 - val_loss: 3.2479\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:14<00:00,  4.88s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 - train_loss: 3.2384 - val_loss: 3.2091\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:14<00:00,  4.82s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 - train_loss: 3.2250 - val_loss: 3.1397\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:14<00:00,  4.79s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 - train_loss: 2.9985 - val_loss: 3.0971\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:14<00:00,  4.70s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 - train_loss: 3.2266 - val_loss: 3.0749\n",
      "âœ… Guardado mejor modelo como ocr_ctc_full.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val = float('inf')\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    tr_loss = train_epoch(train_loader)\n",
    "    val_loss = val_epoch(val_loader)\n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS} - train_loss: {tr_loss:.4f} - val_loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Guardar el mejor modelo\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        torch.save(model, \"/kaggle/working/ocr_ctc_full.pt\")\n",
    "        print(\"âœ… Guardado mejor modelo como ocr_ctc_full.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8634869,
     "sourceId": 13602558,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 413.453141,
   "end_time": "2025-11-04T11:14:22.033489",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-04T11:07:28.580348",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
