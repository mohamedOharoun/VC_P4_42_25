{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb7f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import easyocr\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9cf8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Detector YOLO\n",
    "detector = YOLO(\"models/yolo11n_best.pt\")\n",
    "\n",
    "# EasyOCR (idiomas español e inglés)\n",
    "reader_easy = easyocr.Reader(['es', 'en'])\n",
    "\n",
    "# Definición de CRNN\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1), (2,1)),\n",
    "            nn.Conv2d(256, 512, 3, 1, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1), (2,1))\n",
    "        )\n",
    "        self.rnn = nn.LSTM(512, 256, num_layers=2, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.view(b, c*h, w).permute(0, 2, 1)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Carga del modelo CRNN\n",
    "model_crnn = torch.load(\"models/ocr_v3.pt\", map_location=device)\n",
    "model_crnn.eval()\n",
    "print(\"✅ Modelo CRNN cargado correctamente.\")\n",
    "\n",
    "# Transformaciones para CRNN\n",
    "transform = T.Compose([\n",
    "    T.Grayscale(),\n",
    "    T.Resize((32, 128)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# Diccionario de caracteres\n",
    "CHARS = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "idx_to_char = {i: c for i, c in enumerate(CHARS)}\n",
    "\n",
    "def decode_ctc(output):\n",
    "    \"\"\"Decodifica la salida CTC en texto.\"\"\"\n",
    "    pred = output.softmax(2).argmax(2).squeeze(0).cpu().numpy()\n",
    "    text = \"\"\n",
    "    prev_char = -1\n",
    "    for c in pred:\n",
    "        if c != prev_char and c < len(CHARS):\n",
    "            text += idx_to_char.get(c, \"\")\n",
    "        prev_char = c\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95200b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO = \"plates_test.mp4\"\n",
    "cap = cv2.VideoCapture(VIDEO)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = 0\n",
    "data_rows = []\n",
    "\n",
    "print(\"Procesando vídeo...\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "    timestamp = datetime.fromtimestamp((frame_count / fps)).strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "    results = detector(frame, verbose=False)\n",
    "\n",
    "    if results[0].boxes:\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            placa = frame[y1:y2, x1:x2]\n",
    "            if placa.size == 0:\n",
    "                continue\n",
    "\n",
    "            # EASY OCR\n",
    "            try:\n",
    "                text_easy = reader_easy.readtext(placa, detail=0, allowlist=CHARS)\n",
    "                text_easy = max(text_easy, key=len).replace(\" \", \"\") if text_easy else \"\"\n",
    "            except:\n",
    "                text_easy = \"\"\n",
    "\n",
    "            # CRNN (modelo propio)\n",
    "            try:\n",
    "                placa_rgb = cv2.cvtColor(placa, cv2.COLOR_BGR2RGB)\n",
    "                img_pil = Image.fromarray(placa_rgb)\n",
    "                img_t = transform(img_pil).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model_crnn(img_t)\n",
    "                text_crnn = decode_ctc(out)\n",
    "            except:\n",
    "                text_crnn = \"\"\n",
    "\n",
    "            data_rows.append({\n",
    "                \"Frame\": frame_count,\n",
    "                \"Tiempo\": timestamp,\n",
    "                \"EasyOCR\": text_easy,\n",
    "                \"CRNN_Custom\": text_crnn\n",
    "            })\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Guardar resultados\n",
    "df = pd.DataFrame(data_rows)\n",
    "df.to_csv(\"comparacion_ocr_v3_yolo11n.csv\", index=False)\n",
    "print(\"✅ Comparación completada.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4_fix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
